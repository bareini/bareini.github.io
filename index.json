[{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://bareini.github.io/author/bar-eini-porat/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/bar-eini-porat/","section":"authors","summary":"","tags":null,"title":"Bar Eini-Porat","type":"authors"},{"authors":[],"categories":[],"content":"","date":1598873358,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598873358,"objectID":"c53fee0ae17c9ec843738995c4396292","permalink":"https://bareini.github.io/project/doodle/","publishdate":"2020-08-31T14:29:18+03:00","relpermalink":"/project/doodle/","section":"project","summary":"In this short project, we propose algorithms to mitigate scoial bias of open polls. We do this by approximating open voting profiles to their theotical hidden counterparts and de-biasing the an open poll's final outcome, hopefully maximizing social utility.","tags":[],"title":" Debiasing Doodle Polls","type":"project"},{"authors":[],"categories":[],"content":"","date":1598872082,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598872082,"objectID":"f7cfea511ea1606d121887c283400b12","permalink":"https://bareini.github.io/project/interpt/","publishdate":"2020-08-31T14:08:02+03:00","relpermalink":"/project/interpt/","section":"project","summary":"In this work, we incorporate existing tools for interpretability of machine learning models such as LIME, SHAP and MMD-critic to gain a better understading of AI models. These hybrids are then evaluated to detemine which provaids better explanations.","tags":[],"title":"Interpretability of AI Models in Healthcare Senarios ","type":"project"},{"authors":[],"categories":[],"content":"","date":1598870644,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598870644,"objectID":"082aad22b9355065270accf32d314b2e","permalink":"https://bareini.github.io/project/cud/","publishdate":"2020-08-31T13:44:04+03:00","relpermalink":"/project/cud/","section":"project","summary":"This work investigates possible mediators for developing cannabis use disorder (CUD). It takes a partial correlation approach for the analysis of trios with possible causal relationships and build on graph theory to deduce the true relationships and idetify mediators. ","tags":[],"title":"Mediators for Cannabis Use Disorder","type":"project"},{"authors":[],"categories":[],"content":"","date":1598864670,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598864670,"objectID":"8db09040d6d4212d3fbc3cad69d21316","permalink":"https://bareini.github.io/publication/discovery/","publishdate":"2020-08-31T12:04:30+03:00","relpermalink":"/publication/discovery/","section":"publication","summary":"In this study we propose a novel method of “removing” known, hand-engineered features from the network’s hypothesis space, thus forcing it to try learn representations which are different from known ones, as a method of scientific exploration. We then build on existing work in the field of interpretability, specifically class activation maps, to try infer what new features the network has learned.","tags":[],"title":"Using deep networks for scientific discovery in physiological signals","type":"publication"}]